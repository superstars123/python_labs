## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if not nums:
        raise ValueError("–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫!!!")
    m1=min(nums)
    m2=max(nums)
    return(m1, m2)
print(min_max([3, -1, 5, 5, 0]))
print(min_max([42]))
print(min_max([-5, -2, -9]))
print(min_max([1.5, 2, 2.0, -3.1]))
print(min_max([]))
```
![ex01](scr/lab02/images/ex1.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
def unique_sorted(nums):
    return sorted(set(nums))
print(unique_sorted([3, 1, 2, 1, 3]))
print(unique_sorted([]))
print(unique_sorted([-1, -1, 0, 2, 2]))
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))

```

![ex02](scr/lab02/images/ex2.png)


### –ó–∞–¥–∞–Ω–∏–µ 3
```python
def flatten(mat: list[list | tuple]) -> list:
    a=[]
    for i in mat:
        for j in i:
            if str(j) in "0123456789":
                a.append(j)
            else:
                raise "TypeError"
    return a
print(flatten([[1, 2], [3, 4]]))
print(flatten(([1, 2], (3, 4, 5))))
print(flatten([[1], [], [2, 3]]))
print(flatten([[1, 2], "ab"]))

```
![ex03](scr/lab02/images/ex3.png)

### –ó–∞–¥–∞–Ω–∏–µ 4
```python
def transpose(mat: list[list[float | int]]) -> list[list]:
    if not mat:
        return []

    rw_len = len(mat[0])
    for rw in mat:
        if len(rw) != rw_len:
            raise 'ValueError'

    rw, cl = len(mat), rw_len
    result = []

    for j in range(cl):
        new_rw = []
        for i in range(rw):
            new_rw.append(mat[i][j])
        result.append(new_rw)
    return result


print(transpose([[1, 2, 3]]))
print(transpose([[1], [2], [3]]))
print(transpose([[1, 2], [3, 4]]))
print(transpose([]))
print(transpose([[1, 2], [3]]))
```
![ex04](scr/lab02/images/ex4.png)

### –ó–∞–¥–∞–Ω–∏–µ 5
```python
def row_sums(mat: list[list[float | int]]) -> list[float]:
    if not mat or any(len(row) != len(mat[0]) for row in mat): raise ValueError
    return [float(sum(row)) for row in mat]


print(row_sums([[1, 2, 3], [4, 5, 6]]))
print(row_sums([[-1, 1], [10, -10]]))
print(row_sums([[0, 0], [0, 0]]))
print(row_sums([[1, 2], [3]]))
```
![ex05](scr/lab02/images/ex5.png)

### –ó–∞–¥–∞–Ω–∏–µ 6
```python
def col_sums(mat: list[list[float | int]]) -> list[float]:
    if not mat:
        return []

    rw_len = len(mat[0])
    for rw in mat:
        if len(rw) != rw_len:
            raise 'ValueError'

    rw, cl = len(mat), rw_len
    result = []

    for j in range(cl):
        t = 0
        for i in range(rw):
            t += mat[i][j]
        result.append(float(t))
    return result


print(col_sums([[1, 2, 3], [4, 5, 6]]))
print(col_sums([[-1, 1], [10, -10]]))
print(col_sums([[0, 0], [0, 0]]))
print(col_sums([[1, 2], [3]]))
```
![ex06](scr/lab02/images/ex6.png)

### –ó–∞–¥–∞–Ω–∏–µ 7
```python
def format_record(student: tuple[str, str, float]) -> str:
    if len(student) != 3:
        raise "ValueError"
    if not (isinstance(student[0], str) and isinstance(student[1], str) and isinstance(student[2],float)):
        return "TypeError"
    fio_parts = student[0].split()
    result = fio_parts[0].title() + " " + fio_parts[1][0].upper()
    if len(fio_parts) == 3:
        result += "." + fio_parts[2][0].upper() + "., "
    else:
        result += "., "
    result += "–≥—Ä. " + student[1] + ", GPA " + f"{round(student[2], 2):.2f}"
    return result

a = ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)
b = ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)
c = ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)
d = ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)
x = (" ", " ",1)
print(format_record(a))
print(format_record(b))
print(format_record(c))
print(format_record(d))
print(format_record(x))
```
![ex07](scr/lab02/images/exx7.png)()



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3

### normalize
```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:#casefold –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    text = text.casefold()
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    text = text.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ') #–æ—Ç—Å—Ç—É–ø,–∫—É—Ä—Å–æ—Å—Ä –≤ –Ω–∞—á–∞–ª–æ —Å—Ç–æ—Ä–∫–∏,–ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–æ–∫—É –Ω–∏–∂–µ
    text = ' '.join(text.split()) #—Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –ø–æ –ø—Ä–æ–±–µ–ª–º–∞ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ —Å –æ–¥–Ω–∏–º –ø—Ä–æ–±–µ–ª–æ–º 
    text = text.strip() #—É–¥–∞–ª—è–µ—Ç –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
    return text
print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t")) 
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
print(normalize("Hello\r\nWorld"))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))


```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](lab03/images/ex1.png)

### tokenize
```python
import re #–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏
def tokenize(text: str) -> list[str]:
    return re.findall(r'\w+(?:-\w+)*', text)
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
```
    
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](lab03/images/ex2.png)


### count_freq + top_n
```python
def count_freq(tokens: list[str]) -> dict[str, int]:
    cnt = {}  
    for w in tokens:
        cu = cnt.get(w, 0)
        cnt[w] = cu + 1
    return cnt
def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    t = []
    for w, count in freq.items():#–ø–æ–ª—É—á–∞–µ–º –ø–∞—Ä—ã(—Å–ª–æ–≤–æ,–∫–æ–ª-–≤–æ)
        t.append((-count, w))#—Å–æ–∑–¥–∞–µ–º –∫–æ—Ä—Ç–µ–∂(–º–∏–Ω—É—Å –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
    t.sort()
    result = []
    for neg_count, w in t:
        result.append((w, -neg_count))#(- –¥–ª—è –∫–æ—Å–ø–µ–Ω—Å–∞—Ü–∏–∏ –ø—Ä–µ–¥ –º–∏–Ω—É—Å–∞)
    return result[:n]
tok = ["a", "b", "a", "c", "b", "a"]
freq = count_freq(tok)
print(top_n(freq, n=2))
tok_2 = ["bb", "aa", "bb", "aa", "cc"]
freq_2 = count_freq(tok_2)
print(top_n(freq_2, n=2))

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](lab03/images/ex3.png)

### src/text_stats.py 
```python
from lib.text import normalize, tokenize, count_freq, top_n
import sys
def main():
    text = sys.stdin.buffer.read().decode('utf-8') #–≤—Ö–æ–¥ –∫ –±–∏–Ω–∞—Ä–Ω—ã–º –¥–∞–Ω–Ω—ã–º,–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ —é–Ω–∏–∫–æ–¥
    if not text.strip():
        print("–ù–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        return
    normalized_text = normalize(text)
    tokens = tokenize(normalized_text)
    

    if not tokens:
        print("–í —Ç–µ–∫—Å—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤")
        return

    total_words = len(tokens) # –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
    freq_dict = count_freq(tokens) # —Å–ª–æ–≤–∞—Ä—å —á–∞—Å—Ç–æ—Ç
    unique_words = len(freq_dict) # –∫–æ–ª–∏—á–µ—Å–∏—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ 
    top_words = top_n(freq_dict, 5) # —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã
    
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
    print("–¢–æ–ø-5:")
    for word, count in top_words:
        print(f"{word}: {count}")


if __name__ == "__main__":  
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](lab03/images/ex4.png)
# –õ–∞–±–æ—Ä—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4
## –ó–∞–¥–∞–Ω–∏–µ A ‚Äî io_txt_csv.py
```python
import csv
from pathlib import Path
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    try:
        return Path(path).read_text(encoding=encoding)
    except FileNotFoundError:
        return "–¢–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç—É"
    except UnicodeDecodeError:
        return "–ù–µ—É–¥–∞–ª–æ—Å—å –∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É"

def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    with p.open('w', newline="", encoding="utf-8") as file: # –∫–æ–Ω—Ç—Ä–æ–ª—å –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫,–∫–æ–¥–∏—Ä–æ–≤–≤–∫–∞ —Ñ–∞–π–ª–∞
        f = csv.writer(file)
        if header is None and rows == []: # –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –¥–∞–Ω–Ω—ã—Ö
            file_c.writerow(('a', 'b')) 
        if header is not None:
            f.writerow(header)
        if rows != []:
            const = len(rows[0])
            for i in rows:
                if len(i) != const:
                    return ValueError
        f.writerows(rows)

def ensure_parent_dir(path: str | Path) -> None:
    Path(path).parent.mkdir(parents=True, exist_ok=True)

print(read_text(r"c:\Users\1\python_labs\data\input.txt"))
write_csv([("word","count"),("test",3)], r"c:\Users\1\python_labs\data\check.csv") 
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](laba_4/images/ex1.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](laba_4/images/ex1.1.png)

## –ó–∞–¥–∞–Ω–∏–µ B ‚Äî text_report.py
```python
from io_txt_csv import read_text, write_csv, ensure_parent_dir
import sys
from pathlib import Path

sys.path.append(r'c:\Users\1\python_labs\lib')

from lib.text import normalize, tokenize, count_freq, top_n

def exist_path(path_f: str):
    return Path(path_f).exists()


def main(file: str, encoding: str = 'utf-8'):
    if not exist_path(file):
        raise FileNotFoundError
    
    file_path = Path(file)
    text = read_text(file, encoding=encoding)
    norm = normalize(text)
    tokens = tokenize(norm)
    freq_dict = count_freq(tokens)
    top = top_n(freq_dict, 5)
    top_sort = sorted(top, key=lambda x: (x[1], x[0]), reverse=True)
    report_path = file_path.parent / 'report.csv'
    write_csv(top_sort, report_path, header=('word', 'count'))
    
    print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}')
    print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq_dict)}')
    print('–¢–æ–ø-5:')
    for cursor in top_sort:
        print(f'{cursor[0]}: {cursor[-1]}')


main(r'c:\Users\1\python_labs\data\input.txt')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](laba_4/images/ex2.2.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](laba_4/images/ex2.png)